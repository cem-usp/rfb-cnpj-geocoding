```{r}
#| label: setup
#| include: false

library(here)

source(here("R", "_setup.R"))
```

<!-- badges: start -->
[![Project Status: WIP – Initial development is in progress, but there has not yet been a stable, usable release suitable for the public.](https://www.repostatus.org/badges/latest/wip.svg)](https://www.repostatus.org/#wip)
[![](https://img.shields.io/badge/OSF-10.17605/OSF.IO/2X6JB-1284C5.svg)](https://doi.org/10.17605/OSF.IO/2X6JB)
[![License: GPLv3](https://img.shields.io/badge/license-GPLv3-bd0000.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/license-CC_BY--NC--SA_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
<!-- badges: end -->

::: {.callout-important}
This pipeline is a **Work In Progress** (WIP) and is under active development. It may not yet be stable or suitable for public use. Please use it with caution and report any issues you encounter.
:::

## Overview

This report provides a fully reproducible pipeline for processing and [geocoding](https://en.wikipedia.org/wiki/Address_geocoding) [CNPJ](https://en.wikipedia.org/wiki/CNPJ)s from the Brazilian Federal Revenue Service ([RFB](https://www.gov.br/receitafederal/)).

## Problem

The [AcessoSAN](https://doi.org/10.17605/OSF.IO/ZE6WT) project aims to develop methods for measuring and analyzing inequities in access to healthy food in favelas and other urban communities. Achieving this requires a reliable and up-to-date database of food retail establishments.

The Brazilian Federal Revenue Service ([RFB](https://www.gov.br/receitafederal/)) [CNPJ](https://en.wikipedia.org/wiki/CNPJ)s database lists companies operating in Brazil, including food retail establishments. However, it does not provide [geocoded information](https://en.wikipedia.org/wiki/Address_geocoding), which is required for spatial analyses. This pipeline addresses that gap by processing and [geocoding](https://en.wikipedia.org/wiki/Address_geocoding) the data.

## Data Availability

::: {style="text-align: left;"}
[![](https://img.shields.io/badge/OSF-10.17605/OSF.IO/2X6JB-1284C5.svg)](https://doi.org/10.17605/OSF.IO/2X6JB)
:::

The processed data are available in both [`rds`](https://rdrr.io/r/base/readRDS.html) and [`csv`](https://en.wikipedia.org/wiki/Comma-separated_values) formats through a dedicated repository on the Open Science Framework ([OSF](https://osf.io/)), accessible [here](https://doi.org/10.17605/OSF.IO/2X6JB). A metadata file is included alongside the validated datasets. You can also retrieve these files directly from [R](https://www.r-project.org/) using the [`osfr`](https://docs.ropensci.org/osfr/) package.

## Methods

### Source of Data

The data used in this report come from the following sources:

- Brazilian Federal Revenue Service ([RFB](https://www.gov.br/receitafederal/)):
  - Data on food retail establishments from the [CNPJ database](https://dados.gov.br/dados/conjuntos-dados/cadastro-nacional-da-pessoa-juridica---cnpj), used for company identification.
  - Data on [Brazilian agencies and municipalities](https://dados.gov.br/dados/conjuntos-dados/tabela-de-rgos-e-municpios) (_Tabela de Órgãos e Municípios_).
- Brazilian Institute of Geography and Statistics ([IBGE](https://www.ibge.gov.br/)): Open spatial datasets of Brazilian addresses from the National Address Register for Statistical Purposes ([CNEFE](https://www.ibge.gov.br/estatisticas/sociais/populacao/38734-cadastro-nacional-de-enderecos-para-fins-estatisticos.html)), used for geocoding via the [`geocodebr`](https://ipeagit.github.io/geocodebr/) R package.

### Data Munging

The data munging follow the data science workflow outlined by @wickham2023e, as illustrated in [@fig-wickham-at-al-2023-figure-1]. All processes were made using the [Quarto](https://quarto.org/) publishing system [@allaire], the [R programming language](https://www.r-project.org/) [@rcoreteama] and several R packages.

Spatial data processing was performed using the [`terra`](https://rspatial.github.io/terra/reference/terra-package.html) R package [@hijmans] and the [rspatial](https://rspatial.org/) framework. For data manipulation and workflow, priority was given to packages from the [tidyverse](https://www.tidyverse.org/) and [rOpenSci](https://ropensci.org/) ecosystems, as well as other packages adhering to the tidy tools manifesto [@wickham2023c].

::: {#fig-wickham-at-al-2023-figure-1}
![](images/wickham-at-al-2023-figure-1.png){width=75%}

[Source: Reproduced from @wickham2023e.]{.legend}

Data science workflow created by Wickham, Çetinkaya-Runde, and Grolemund.
:::

### Code Style

The Tidyverse [code style guide](https://style.tidyverse.org/) and [design principles](https://design.tidyverse.org/) were followed to ensure consistency and enhance readability.

### Reproducibility

The pipeline is fully reproducible and can be run again at any time. To ensure consistent results, the [`renv`](https://rstudio.github.io/renv/) package [@usheya] is used to manage and restore the R environment. See the [README](https://github.com/cem-usp/rfb-cnpj-geocoding/blob/main/README.md) file in the code repository to learn how to run it.

## Set the Environment

### Load Packages

```{r}
#| label: Set the Environment
#| code-fold: false
#| output: false

library(askpass)
library(brandr)
library(beepr)
library(curl)
library(dplyr)
library(fs)
library(geobr)
library(geocodebr)
library(ggplot2)
library(ggspatial)
library(googlesheets4)
library(here)
library(htmltools)
library(lockr) # github.com/danielvartan/lockr
library(magrittr)
library(nanoparquet)
library(orbis) # github.com/danielvartan/orbis
library(osfr)
library(purrr)
library(readr)
library(rvest)
library(rutils) # github.com/danielvartan/rutils
library(sf)
library(stringi)
library(stringr)
library(tidyr)
library(vroom)
library(zip)
```

### Set Keys

```{r}
osf_pat <- Sys.getenv("OSF_PAT") # askpass()
```

```{r}
#| output: false

osf_auth(osf_pat)
```

```{r}
public_key <- here("_ssh", "id_rsa.pub")
```

```{r}
private_key <- here("_ssh", "id_rsa")
```

```{r}
password <- Sys.getenv("ACESSOSAN_PASSWORD") # askpass()
```

### Set Google Sheets API

```{r}
#| output: false

gs4_auth(cache = ".secrets")
```

### Set Input and Output Paths

```{r}
raw_data_dir <- here("data-raw")
data_dir <- here("data")
```

```{r}
for (i in c(raw_data_dir, data_dir)) {
  if (!dir_exists(i)) dir_create(i, recurse = TRUE)
}
```

### Set Initial Variables

```{r}
set.seed(2025)
```

```{r}
year <- 2025
```

```{r}
month <- 1
```

```{r}
municipalities <- c( # IBGE Codes
  3550308 # , # São Paulo
  2507507, # João Pessoa
  3106200, # Belo Horizonte
  4314902, # Porto Alegre
  1721000, # Palmas
  5300108, # Brasília
  5208707  # Goiânia
)
```

## Download CNAE Classification Table

```{r}
#| label: Download CNAE Classification Table

classification_data <-
  read_sheet(
    ss = "1ipCw2FM3aUOdRd4w55J5SUEgXDCogxWZF-NZi0A-o_4",
    sheet = "Dataset"
  ) |>
  mutate(
    g0 = if_else(
      g1_g2 == TRUE & g3 == FALSE & g4 == FALSE,
      TRUE,
      FALSE
    )
  )

classification_data |> glimpse()
```

## Download Data on Brazilian Agencies and Municipalities

```{r}
#| label: Download Data on Brazilian Agencies and Municipalities
#| eval: false

url <- "https://www.gov.br/receitafederal/dados/municipios.csv"
```

```{r}
#| eval: false

curl_download(url, destfile = file.path(raw_data_dir, "municipios.csv"))
```

## Download the RFB Raw Data

### Set Parameters

```{r}
#| label: Download the RFB Raw Data
#| eval: false

if (dir_exists(raw_data_dir)) {
  dir_delete(raw_data_dir)
  dir_create(raw_data_dir, recurse = TRUE)
}
```

### Download Files

```{r}
root <- file.path( # Don´t change the function!
    "https://arquivos.receitafederal.gov.br",
    "dados",
    "cnpj",
    "dados_abertos_cnpj"
  )
```

```{r}
path <- root |> file.path(paste0("2025-", str_pad(month, 2, pad = 0)))

urls <-
  path |>
  read_html() |>
  html_elements("a") |>
  html_attr("href") |>
  str_subset("\\.zip$") %>%
  file.path(path, .)
```

```{r}
urls |>
  map_dbl(.f = get_file_size, .progress = TRUE) |>
  sum() |>
  as_fs_bytes()
```

```{r}
#| eval: false

urls |> download_file(dir = raw_data_dir)
```

```{r}
#| include: false

# beep()
```

### Unzip Files

```{r}
#| eval: false

zip_files <- raw_data_dir |> dir_ls(type = "file", regexp = "\\.zip$")
```

```{r}
#| eval: false
#| output: false

zip_files |> map(\(x) unzip(x, exdir = raw_data_dir), .progress = TRUE)
```

```{r}
#| eval: false

zip_files |> file_delete()
```

## Read TOM Municipality Codes

```{r}
municipalities_tom_data <-
  raw_data_dir |>
  path("municipios.csv") |>
  read_delim(
    delim = ";",
    col_names = FALSE,
    col_types = cols(.default = "c"),
    progress = FALSE
  ) |>
  slice(-1) |>
  mutate(
    across(
      .cols = everything(),
      .fns = \(x) iconv(x, from = "Windows-1252", to = "UTF-8") # iconvlist()
    )
  ) |>
  rename_with(
    \(x) c(
    "municipality_code_tom",
    "municipality_code_ibge",
    "municipality_tom",
    "municipality_ibge",
    "uf"
    )
  ) |>
  mutate(
    municipality_code_tom = as.integer(municipality_code_tom),
    municipality_code_ibge = as.integer(municipality_code_ibge)
  )
```

```{r}
municipalities_tom_data |> glimpse()
```

## Replace IBGE Municipality Codes with TOM Codes

```{r}
municipalities <-
  municipalities_tom_data |>
  filter(municipality_code_ibge %in% municipalities) |>
  pull(municipality_code_tom)
```

```{r}
municipalities
```

## Read the Data

```{r}
#| label: Read the Data

establishment_data <-
  raw_data_dir |>
  dir_ls(type = "file", regexp = "\\.ESTABELE$") |>
  map(
    function(x) {
      vroom(
        # Uses `pipe()` and `awk` to filter data to avoid loading the
        # entire file into memory.
        file = pipe(
          paste0(
            "awk ",
            "-F ",
            "';' ",
            "'{ ",
            "if (",
            '$6 == "', '\\"02\\"', '"',
            " && ",
            paste0('$21 == "\\"', municipalities, '\\""', collapse = " || "),
            " && ",
            '$29 == "', '\\"\\"', '"',
            ") ",
            "print",
            " }' ",
            x
          )
        ),
        delim = ";",
        col_names = c(
          "cnpj_basic",
          "cnpj_order",
          "cnpj_dv",
          "branch_identifier",
          "trade_name",
          "registration_status",
          "registration_status_date",
          "registration_status_reason",
          "foreign_city_name",
          "country",
          "start_date",
          "cnae_primary",
          "cnae_secondary",
          "street_type",
          "street_name",
          "number",
          "address_complement",
          "neighborhood",
          "postal_code",
          "federal_unit",
          "municipality_code_tom",
          "phone_area_code_1",
          "phone_number_1",
          "phone_area_code_2",
          "phone_number_2",
          "fax_area_code",
          "fax_number",
          "email",
          "special_status",
          "special_status_date"
        ),
        col_types = cols(.default = "c"),
        col_select = c(
          "cnpj_basic", "cnpj_order", "cnpj_dv", "cnae_primary",
          "federal_unit", "municipality_code_tom", "street_type",
          "street_name", "number", "address_complement", "neighborhood",
          "postal_code"
        ),
        show_col_types = FALSE
      )
    },
    .progress = TRUE
  ) |>
    list_rbind()
```

```{r}
establishment_data |> glimpse()
```

## Filter the Data

```{r}
#| label: Filter the Data

establishment_data <-
  establishment_data |>
  mutate(cnae = str_pad(cnae_primary, 7, pad = "0")) |>
  left_join(classification_data, by = c("cnae", "federal_unit")) |>
  drop_na(g0, g1_g2, g3, g4)
```

```{r}
establishment_data |> glimpse()
```

## Tidy the Data

```{r}
#| label: Tidy the Data

establishment_data <-
  establishment_data |>
  mutate(municipality_code_tom = as.integer(municipality_code_tom)) |>
  left_join(municipalities_tom_data, by = "municipality_code_tom") |>
  rename(
    municipality_code = municipality_code_ibge,
    municipality = municipality_ibge,
    complement = address_complement
  ) |>
  mutate(
    cnpj_basic = str_pad(cnpj_basic, 8, pad = "0"),
    cnpj_order = str_pad(cnpj_order, 4, pad = "0"),
    cnpj_dv = str_pad(cnpj_dv, 2, pad = "0"),
    cnpj = paste0(
      str_sub(cnpj_basic, 1, 2),
      ".", str_sub(cnpj_basic, 3, 5),
      ".", str_sub(cnpj_basic, 6, 8),
      "/", cnpj_order,
      "-", cnpj_dv
    ),
    cnae = paste0(
      str_sub(cnae, 1, 4),
      "-", str_sub(cnae, 5, 5),
      "/", str_sub(cnae, 6, 7)
    ),
    street_type = str_to_title(street_type),
    street_name = str_to_title(street_name),
    address =
      paste(street_type, street_name) |>
      iconv(to = "ASCII//TRANSLIT"),
    number =
      number |>
      iconv(to = "ASCII//TRANSLIT") |>
      str_remove_all("\\D") |>
      str_trim() |>
      as.numeric() |>
      as.character() |>
      suppressWarnings(),
    complement = str_to_title(complement),
    neighborhood = str_to_title(neighborhood),
    postal_code =
      postal_code |>
      as.numeric() |>
      str_pad(pad = 0, width = 8)
  ) |>
  select(
    cnpj, cnae,
    federal_unit, municipality_code, municipality,
    address, number, complement, neighborhood, postal_code,
    g0, g1_g2, g3, g4
  ) |>
  mutate(
    across(
      .cols = where(is.character),
      .fns = function(x) {
          Encoding(x) <- "UTF-8"

          iconv(x, from = "", to = "UTF-8", sub = "")
      }
    )
  )
```

```{r}
establishment_data |> glimpse()
```

## Arrange the Data

```{r}
#| label: Arrange the Data

establishment_data <-
  establishment_data |>
  arrange(federal_unit, municipality, cnae)
```

```{r}
establishment_data |> glimpse()
```

## Geocode the Data

```{r}
#| label: Geocode the Data

fields <- definir_campos(
  estado = "federal_unit",
  municipio = "municipality_code",
  logradouro = "address",
  numero = "number",
  cep = "postal_code",
  localidade = "neighborhood"
)
```

```{r}
establishment_data <-
  establishment_data |>
  geocode(
    campos_endereco = fields,
    resultado_sf = FALSE,
    verboso = TRUE,
    cache = TRUE,
    n_cores = 1,
    resolver_empates = TRUE
  )
```

```{r}
establishment_data <-
  establishment_data |>
  as_tibble() |>
  rename(
    latitude = lat,
    longitude = lon,
    geocodebr_precision = precisao,
    geocodebr_type_of_result = tipo_resultado,
    geocodebr_deviation_meters = desvio_metros,
    geocodebr_address_found = endereco_encontrado,
    geocodebr_ambiguous = empate
  ) |>
  relocate(g0, g1_g2, g3, g4, .after = geocodebr_ambiguous) |>
  drop_na(all_of(c("latitude", "longitude")))
```

```{r}
establishment_data |> glimpse()
```

## Data Dictionary

## Save the Valid Data

## Visualize the Data

### Set Variables

```{r}
#| label: Visualize the Data

plot_municipality <- 3550308 # São Paulo
```

### Set Shape

```{r}
shape <-
  plot_municipality |>
  read_municipality(year = closest_geobr_year(year)) |>
  st_transform(st_crs(4326))
```

### Prepare Data

```{r}
plot_data <-
  establishment_data |>
  filter(municipality_code == plot_municipality) |>
  pivot_longer(
    cols = all_of(c("g0", "g1_g2", "g3", "g4")),
    names_to = "group",
    values_to = "value"
  ) |>
  filter(value == TRUE) |>
  st_as_sf(
    coords = c("longitude", "latitude"),
    crs = 4326
  ) |>
  st_join(shape, join = st_within, left = FALSE) %>%
  mutate(
    latitude = st_coordinates(.)[,2],
    longitude = st_coordinates(.)[,1]
  ) |>
  st_drop_geometry() |>
  transmute(
    group =
      group |>
      str_to_upper() |>
      str_replace("_", "-"),
    latitude,
    longitude
  )
```

```{r}
plot_data |> glimpse()
```

### Plot Data

```{r}
#| label: Test Plot
#| fig-width: 10
#| fig-height: 4

ggplot() +
  geom_sf(
    data = shape,
    fill = "gray90",
    color = "black"
  ) +
  geom_point(
    data = plot_data,
    mapping = aes(x = longitude, y = latitude, color = group),
    size = 0.01
  ) +
  facet_wrap(~ group, ncol = 4) +
  coord_sf(crs = 4326) +
  scale_x_continuous(labels = NULL, breaks = NULL) +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  scale_colour_brand_d() +
  theme(legend.position = "none") +
  labs(x = NULL, y = NULL, color = NULL)
```

## Citation

::: {.callout-important}
When using this data, you must also cite the original data sources.
:::

To cite this work, please use the following format:

Vartanian, D., Penz, C. L. S., Caldeira, G., Fernandes, C. N., & Giannotti, M. A. (2025). *A reproducible pipeline for processing and geocoding CNPJs from the Brazilian Federal Revenue Service (RFB)* \[Computer software\]. Center for Metropolitan Studies of the University of São Paulo. <https://cem-usp.github.io/rfb-cnpj-geocoding>

A BibTeX entry for LaTeX users is

```latex
@software{vartanian2025,
  title = {A reproducible pipeline for processing and geocoding CNPJs from the Brazilian Federal Revenue Service (RFB)},
  author = {{Daniel Vartanian} and {Clara de Lima e Silva Penz} and {Gabriel Caldeira} and {Camila Nastari Fernandes} and {Mariana Abrantes Giannotti}},
  year = {2025},
  address = {São Paulo},
  institution = {Center for Metropolitan Studies of the University of São Paulo},
  langid = {en},
  url = {https://cem-usp.github.io/rfb-cnpj-geocoding}
}
```

## License

::: {style="text-align: left;"}
[![License: GPLv3](https://img.shields.io/badge/license-GPLv3-bd0000.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/license-CC_BY--NC--SA_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
:::

::: {.callout-important}
The original data sources may be subject to their own licensing terms and conditions.
:::

The code in this repository is licensed under the [GNU General Public License Version 3](https://www.gnu.org/licenses/gpl-3.0), while the report is available under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/).

``` text
Copyright (C) 2025 Center for Metropolitan Studies

The code in this report is free software: you can redistribute it and/or
modify it under the terms of the GNU General Public License as published by the
Free Software Foundation, either version 3 of the License, or (at your option)
any later version.

This program is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program. If not, see <https://www.gnu.org/licenses/>.
```

## Acknowledgments

```{r, results='asis'}
#| eval: true
#| echo: false

blocks <- list(
  list(
    logo_link = "https://doi.org/10.17605/OSF.IO/ZE6WT",
    logo_src = "images/acessosan-logo.svg",
    logo_alt = "AcessoSAN Logo",
    logo_width = 140,
    text = 'This work is part of a research project by the Polytechnic School (<a href="https://www.poli.usp.br/">Poli</a>) of the University of São Paulo (<a href="https://usp.br/">USP</a>), in partnership with the Secretariat for Food and Nutrition Security (<a href="https://www.gov.br/mds/pt-br/orgaos/SESAN">SESAN</a>) of the Ministry of Social Development, Family, and the Fight Against Hunger (<a href="https://www.gov.br/mds/">MDS</a>), titled: <em>AcessoSAN: Mapping Food Access to Support Public Policies on Food and Nutrition Security and Hunger Reduction in Brazilian Cities</em>.'
  ),
  list(
    logo_link = "https://centrodametropole.fflch.usp.br",
    logo_src = "images/cem-icon.svg",
    logo_alt = "CEM Logo",
    logo_width = 190,
    text = 'This work was developed with support from the Center for Metropolitan Studies (<a href="https://centrodametropole.fflch.usp.br">CEM</a>) based at the School of Philosophy, Letters and Human Sciences (<a href="https://www.fflch.usp.br/">FFLCH</a>) of the University of São Paulo (<a href="https://usp.br">USP</a>) and at the Brazilian Center for Analysis and Planning (<a href="https://cebrap.org.br/">CEBRAP</a>).'
  ),
  list(
    logo_link = "https://fapesp.br/",
    logo_src = "images/fapesp-logo.svg",
    logo_alt = "FAPESP Logo",
    logo_width = 160,
    text = 'This study was financed, in part, by the São Paulo Research Foundation (<a href="https://fapesp.br/">FAPESP</a>), Brazil. Process Number <a href="https://bv.fapesp.br/en/bolsas/231507/geospatial-data-science-applied-to-food-policies/">2025/17879-2</a>.'
  )
)

blocks |>
  lapply(
    function(x) {
      div(
        style = paste0(
          "display: flex; ",
          "align-items: flex-start; ",
          "margin-bottom: 2em;"
        ),
        div(
          style = paste0(
            "flex: 0 0 30%; ",
            "display: flex; ",
            "justify-content: center; ",
            "margin: auto 0;"
          ),
          tags$a(
            href = x$logo_link,
            tags$img(
              src = x$logo_src,
              alt = x$logo_alt,
              style = paste0(
                "max-width: ", x$logo_width, "px; ",
                "width: 100%; ",
                "height: auto;"
              )
            )
          )
        ),
        div(
          style = paste0(
            "flex: 1; ",
            "padding-left: 1em;"
          ),
          HTML(x$text)
        )
      )
    }
  ) |>
  tagList() |>
  browsable()
```

## References {.unnumbered}

::: {#refs}
:::
